{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATASET = r'/media/gagandeep/2E92405C92402AA3/Work/Kaggle/Zips/fake-news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['submit.csv', 'test.csv', 'train.csv']"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "os.listdir(PATH_TO_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id                                              title              author  \\\n0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n\n                                                text  label  \n0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n1  Ever get the feeling your life circles the rou...      0  \n2  Why the Truth Might Get You Fired October 29, ...      1  \n3  Videos 15 Civilians Killed In Single US Airstr...      1  \n4  Print \\nAn Iranian woman has been sentenced to...      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>author</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n      <td>Darrell Lucus</td>\n      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n      <td>Daniel J. Flynn</td>\n      <td>Ever get the feeling your life circles the rou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Why the Truth Might Get You Fired</td>\n      <td>Consortiumnews.com</td>\n      <td>Why the Truth Might Get You Fired October 29, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n      <td>Jessica Purkiss</td>\n      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Iranian woman jailed for fictional unpublished...</td>\n      <td>Howard Portnoy</td>\n      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(PATH_TO_DATASET, 'train.csv'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NA values\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Shape of features: (18285, 4)\nShape of labels: (18285,)\n"
    }
   ],
   "source": [
    "# Get features and label from the data\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "print(\"Shape of features: {}\".format(X.shape))\n",
    "print(\"Shape of labels: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our goal is to build a LSTM model - unidirectional and biderectional to classify fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2.1.0'"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the vocabulary size -> the size of our corpus.\n",
    "voc_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'FLYNN: Hillary Clinton, Big Woman on Campus - Breitbart'"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# One hot representation\n",
    "messages = X.copy()\n",
    "messages['title'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/gagandeep/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 18285/18285 [00:34<00:00, 527.95it/s]\n"
    }
   ],
   "source": [
    "# Pre process the data\n",
    "# The same steps will be used when making predictions\n",
    "import tqdm\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "for i in tqdm.tqdm(range(0, len(messages))):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['hous dem aid even see comey letter jason chaffetz tweet',\n 'flynn hillari clinton big woman campu breitbart',\n 'truth might get fire',\n 'civilian kill singl us airstrik identifi',\n 'iranian woman jail fiction unpublish stori woman stone death adulteri',\n 'jacki mason hollywood would love trump bomb north korea lack tran bathroom exclus video breitbart',\n 'beno hamon win french socialist parti presidenti nomin new york time',\n 'back channel plan ukrain russia courtesi trump associ new york time',\n 'obama organ action partner soro link indivis disrupt trump agenda',\n 'bbc comedi sketch real housew isi caus outrag']"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[3441, 3451, 556, 3166, 921, 376, 4172, 3582, 3283, 1407],\n [2439, 4354, 2190, 4748, 2442, 819, 4010],\n [1622, 1331, 1470, 4593],\n [1761, 4931, 1912, 66, 4824, 3843],\n [1093, 2442, 1449, 4266, 2549, 2050, 2442, 4496, 778, 4130],\n [363,\n  3504,\n  1966,\n  4425,\n  1826,\n  1857,\n  587,\n  2550,\n  3020,\n  2695,\n  2138,\n  4846,\n  1903,\n  130,\n  4010],\n [3922, 1190, 2550, 4479, 3366, 3921, 4612, 3061, 678, 3930, 4758],\n [2593, 3166, 4358, 407, 4870, 1255, 1857, 3956, 678, 3930, 4758],\n [2666, 878, 3710, 2162, 3117, 4944, 578, 4516, 1857, 692],\n [771, 4491, 2848, 958, 906, 3998, 2243, 3960]]"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "onehot_repr = [one_hot(words, voc_size) for words in corpus]\n",
    "onehot_repr[:10]\n",
    "#shape of matrix\n",
    "#18285 x 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to make the length of each sentance uniform, we will define a fixed length and pad all the sentances which are less than the ficed length value\n",
    "fixed_length = 20\n",
    "embedded_docs = pad_sequences(onehot_repr, padding='pre', maxlen=fixed_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 3441,\n        3451,  556, 3166,  921,  376, 4172, 3582, 3283, 1407],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0, 2439, 4354, 2190, 4748, 2442,  819, 4010],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0, 1622, 1331, 1470, 4593],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0, 1761, 4931, 1912,   66, 4824, 3843],\n       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1093,\n        2442, 1449, 4266, 2549, 2050, 2442, 4496,  778, 4130]],\n      dtype=int32)"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "embedded_docs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "# Model Creation - Unidirectional\n",
    "embedding_dim = 40\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, embedding_dim, input_length=fixed_length))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array(embedded_docs)\n",
    "y = np.array(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 12799 samples, validate on 5486 samples\nEpoch 1/15\n12799/12799 [==============================] - 12s 932us/sample - loss: 0.3581 - accuracy: 0.8140 - val_loss: 0.2089 - val_accuracy: 0.9103\nEpoch 2/15\n12799/12799 [==============================] - 8s 644us/sample - loss: 0.1589 - accuracy: 0.9356 - val_loss: 0.2027 - val_accuracy: 0.9167\nEpoch 3/15\n12799/12799 [==============================] - 7s 524us/sample - loss: 0.1255 - accuracy: 0.9558 - val_loss: 0.2024 - val_accuracy: 0.9171\nEpoch 4/15\n12799/12799 [==============================] - 6s 504us/sample - loss: 0.0911 - accuracy: 0.9662 - val_loss: 0.2337 - val_accuracy: 0.9200\nEpoch 5/15\n12799/12799 [==============================] - 6s 492us/sample - loss: 0.0682 - accuracy: 0.9761 - val_loss: 0.2624 - val_accuracy: 0.9156\nEpoch 6/15\n12799/12799 [==============================] - 6s 490us/sample - loss: 0.0546 - accuracy: 0.9815 - val_loss: 0.2805 - val_accuracy: 0.9167\nEpoch 7/15\n12799/12799 [==============================] - 7s 528us/sample - loss: 0.0402 - accuracy: 0.9876 - val_loss: 0.2979 - val_accuracy: 0.9120\nEpoch 8/15\n12799/12799 [==============================] - 8s 623us/sample - loss: 0.0313 - accuracy: 0.9906 - val_loss: 0.3802 - val_accuracy: 0.9160\nEpoch 9/15\n12799/12799 [==============================] - 7s 583us/sample - loss: 0.0302 - accuracy: 0.9914 - val_loss: 0.3259 - val_accuracy: 0.9162\nEpoch 10/15\n12799/12799 [==============================] - 9s 683us/sample - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.3977 - val_accuracy: 0.9160\nEpoch 11/15\n12799/12799 [==============================] - 8s 642us/sample - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.4242 - val_accuracy: 0.9160\nEpoch 12/15\n12799/12799 [==============================] - 7s 563us/sample - loss: 0.0180 - accuracy: 0.9948 - val_loss: 0.3995 - val_accuracy: 0.9171\nEpoch 13/15\n12799/12799 [==============================] - 6s 474us/sample - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.4720 - val_accuracy: 0.9140\nEpoch 14/15\n12799/12799 [==============================] - 6s 483us/sample - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.4643 - val_accuracy: 0.9132\nEpoch 15/15\n12799/12799 [==============================] - 7s 523us/sample - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.4179 - val_accuracy: 0.9167\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f702a7f6e10>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1],\n       [0],\n       [0],\n       ...,\n       [1],\n       [0],\n       [1]], dtype=int32)"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-------------Confusion Matrix -----------------\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[2779,  328],\n       [ 129, 2250]])"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "print(\"-------------Confusion Matrix -----------------\")\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-------------Classification Report -----------------\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'              precision    recall  f1-score   support\\n\\n           0       0.96      0.89      0.92      3107\\n           1       0.87      0.95      0.91      2379\\n\\n    accuracy                           0.92      5486\\n   macro avg       0.91      0.92      0.92      5486\\nweighted avg       0.92      0.92      0.92      5486\\n'"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "print(\"-------------Classification Report -----------------\")\n",
    "classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('LSTM_Uni_dropout.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional\n",
    "# Model Creation - Biidirectional\n",
    "embedding_dim = 40\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, embedding_dim, input_length=fixed_length))\n",
    "model.add(Bidirectional(LSTM(100, activation='relu')))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 12799 samples, validate on 5486 samples\nEpoch 1/15\n12799/12799 [==============================] - 18s 1ms/sample - loss: 0.3408 - accuracy: 0.8421 - val_loss: 0.2052 - val_accuracy: 0.9114\nEpoch 2/15\n12799/12799 [==============================] - 10s 812us/sample - loss: 0.1494 - accuracy: 0.9398 - val_loss: 0.2081 - val_accuracy: 0.9154\nEpoch 3/15\n12799/12799 [==============================] - 11s 864us/sample - loss: 0.1232 - accuracy: 0.9581 - val_loss: 0.2601 - val_accuracy: 0.9120\nEpoch 4/15\n12799/12799 [==============================] - 10s 807us/sample - loss: 0.0772 - accuracy: 0.9712 - val_loss: 0.9507 - val_accuracy: 0.9036\nEpoch 5/15\n12799/12799 [==============================] - 9s 717us/sample - loss: 0.0557 - accuracy: 0.9776 - val_loss: 1.4990 - val_accuracy: 0.9008\nEpoch 6/15\n12799/12799 [==============================] - 9s 725us/sample - loss: 0.0500 - accuracy: 0.9801 - val_loss: 4.0042 - val_accuracy: 0.9045\nEpoch 7/15\n12799/12799 [==============================] - 9s 709us/sample - loss: 0.0346 - accuracy: 0.9870 - val_loss: 8.1045 - val_accuracy: 0.8994\nEpoch 8/15\n12799/12799 [==============================] - 9s 713us/sample - loss: 0.0239 - accuracy: 0.9915 - val_loss: 10.0163 - val_accuracy: 0.9050\nEpoch 9/15\n12799/12799 [==============================] - 9s 715us/sample - loss: 0.0203 - accuracy: 0.9934 - val_loss: 20.5242 - val_accuracy: 0.9069\nEpoch 10/15\n12799/12799 [==============================] - 9s 714us/sample - loss: 0.0179 - accuracy: 0.9945 - val_loss: 47.3534 - val_accuracy: 0.9036\nEpoch 11/15\n12799/12799 [==============================] - 9s 712us/sample - loss: 0.1223 - accuracy: 0.9757 - val_loss: 29.4947 - val_accuracy: 0.9043\nEpoch 12/15\n12799/12799 [==============================] - 9s 715us/sample - loss: 0.0151 - accuracy: 0.9952 - val_loss: 47.2305 - val_accuracy: 0.9027\nEpoch 13/15\n12799/12799 [==============================] - 9s 715us/sample - loss: 0.0066 - accuracy: 0.9986 - val_loss: 62.0011 - val_accuracy: 0.9043\nEpoch 14/15\n12799/12799 [==============================] - 9s 717us/sample - loss: 0.0025 - accuracy: 0.9994 - val_loss: 61.8356 - val_accuracy: 0.8956\nEpoch 15/15\n12799/12799 [==============================] - 9s 714us/sample - loss: 0.0022 - accuracy: 0.9996 - val_loss: 69.2899 - val_accuracy: 0.8943\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f70202ab0b8>"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1],\n       [0],\n       [0],\n       ...,\n       [1],\n       [0],\n       [0]], dtype=int32)"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-------------Confusion Matrix -----------------\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[2826,  281],\n       [ 299, 2080]])"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "print(\"-------------Confusion Matrix -----------------\")\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-------------Classification Report -----------------\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'              precision    recall  f1-score   support\\n\\n           0       0.90      0.91      0.91      3107\\n           1       0.88      0.87      0.88      2379\\n\\n    accuracy                           0.89      5486\\n   macro avg       0.89      0.89      0.89      5486\\nweighted avg       0.89      0.89      0.89      5486\\n'"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "print(\"-------------Classification Report -----------------\")\n",
    "classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('LSTM_Bi_dropout.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bite6955f2e74d64707b01ddae88c9da161",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}